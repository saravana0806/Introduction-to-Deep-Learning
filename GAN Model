Key Concepts:

Generative Adversarial Networks (GANs): GANs consist of a generator and a discriminator working in tandem, creating realistic data and evaluating its authenticity.
Variational Autoencoders (VAEs): VAEs learn a probabilistic mapping between input data and a latent space, allowing for diverse output generation.


Steps to Build Generative AI Models with Python

Data Preparation:
The foundation of any generative AI model lies in its training data. The quality and quantity of data significantly impact the model’s ability to learn and generate meaningful output.

Data Collection: Gather a relevant and comprehensive dataset representing the data type you want your model to generate. For instance, if you’re building a text generator, you’ll need a large corpus of text documents.
Data Preprocessing: Clean and prepare the data for training. This may involve removing irrelevant or noisy data, tokenizing the data into smaller units (e.g., words or sentences), and normalizing the data (e.g., converting text to lowercase).

Model Selection and Implementation:
Choosing a Generative Model Architecture: Select an appropriate generative AI model architecture based on your task and data type. Common choices include Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Recurrent Neural Networks (RNNs) with attention mechanisms.
Model Implementation Using Python Libraries: Utilize Python libraries like TensorFlow or PyTorch to implement the chosen model architecture. This involves defining the model’s layers, activation functions, loss function, and optimizer.

Model Training and Optimization
Training the Generative Model: Divide the dataset into training and validation sets. Train the model using the training data, optimizing its parameters to minimize the loss function. Monitor the model’s performance on the validation set to prevent overfitting.
Hyperparameter Tuning: Refine the model’s hyperparameters (e.g., learning rate, batch size, optimizer settings) to enhance its performance and generalization ability. Employ techniques like grid search or random search to explore different hyperparameter combinations.

Model Evaluation and Generation
Evaluating Model Performance: Assess the trained model’s performance using qualitative and quantitative metrics. Qualitative metrics involve evaluating the generated output’s fluency, coherence, and similarity to the original data. Quantitative metrics can include perplexity, BLEU score, or FID score.
Generating New Data: Unleash the power of the trained model to generate new data samples. Provide the model with a starting prompt or seed, and the model should generate novel data that adheres to the patterns and structures learned from the training data.

1. Generative Adversarial Networks (GANs):
GANs engage in an adversarial dance between a generator and a discriminator
The brilliance of GANs lies in their adversarial training, where the generator and discriminator continuously improve each other in a min-max game. This adversarial elegance enables GANs to generate high-resolution images, realistic faces, and even entirely new artworks. 

2. Variational Autoencoders (VAEs): 
VAEs combine the power of autoencoders with the elegance of probabilistic modeling. At their core, VAEs aim to capture latent structures within data by learning an efficient encoding and decoding process.
An autoencoder is a neural network that learns to copy its input to its output. It consists of an encoder that compresses the input into a latent space representation and a decoder that reconstructs the input from the latent space.

Deep GAN
# code % matplotlib inline
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from IPython import display

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()
x_train = x_train.astype(np.float32) / 255.0
x_test = x_test.astype(np.float32) / 255.0
x_train.shape, x_test.shape

# We plot first 25 images of training dataset
plt.figure(figsize =(10, 10))
for i in range(25):
	plt.subplot(5, 5, i + 1)
	plt.xticks([])
	plt.yticks([])
	plt.grid(False)
	plt.imshow(x_train[i], cmap = plt.cm.binary)
plt.show()

# code
batch_size = 32
# This dataset fills a buffer with buffer_size elements,
# then randomly samples elements from this buffer, 
# replacing the selected elements with new elements.
def create_batch(x_train):
dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)
# Combines consecutive elements of this dataset into batches.

dataset = dataset.batch(batch_size, drop_remainder = True).prefetch(1)
# Creates a Dataset that prefetches elements from this dataset
return dataset
# code
num_features = 100

generator = keras.models.Sequential([
	keras.layers.Dense(7 * 7 * 128, input_shape =[num_features]),
	keras.layers.Reshape([7, 7, 128]),
	keras.layers.BatchNormalization(),
	keras.layers.Conv2DTranspose(
		64, (5, 5), (2, 2), padding ="same", activation ="selu"),
	keras.layers.BatchNormalization(),
	keras.layers.Conv2DTranspose(
		1, (5, 5), (2, 2), padding ="same", activation ="tanh"),
])
generator.summary()

discriminator = keras.models.Sequential([
	keras.layers.Conv2D(64, (5, 5), (2, 2), padding ="same", input_shape =[28, 28, 1]),
	keras.layers.LeakyReLU(0.2),
	keras.layers.Dropout(0.3),
	keras.layers.Conv2D(128, (5, 5), (2, 2), padding ="same"),
	keras.layers.LeakyReLU(0.2),
	keras.layers.Dropout(0.3),
	keras.layers.Flatten(),
	keras.layers.Dense(1, activation ='sigmoid')
])
discriminator.summary()
# compile discriminator using binary cross entropy loss and adam optimizer
discriminator.compile(loss ="binary_crossentropy", optimizer ="adam")
# make discriminator no-trainable as of now
discriminator.trainable = False
# Combine both generator and discriminator
gan = keras.models.Sequential([generator, discriminator])
# compile generator using binary cross entropy loss and adam optimizer

gan.compile(loss ="binary_crossentropy", optimizer ="adam")

seed = tf.random.normal(shape =[batch_size, 100])

def train_dcgan(gan, dataset, batch_size, num_features, epochs = 5):
	generator, discriminator = gan.layers
	for epoch in tqdm(range(epochs)):
		print()
		print("Epoch {}/{}".format(epoch + 1, epochs))

		for X_batch in dataset:
			# create a random noise of sizebatch_size * 100
			# to passit into the generator
			noise = tf.random.normal(shape =[batch_size, num_features])
			generated_images = generator(noise)

			# take batch of generated image and real image and
			# use them to train the discriminator
			X_fake_and_real = tf.concat([generated_images, X_batch], axis = 0)
			y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)
			discriminator.trainable = True
			discriminator.train_on_batch(X_fake_and_real, y1)

			# Here we will be training our GAN model, in this step
			# we pass noise that uses generatortogenerate the image
			# and pass it with labels as [1] So, it can fool the discriminator
			noise = tf.random.normal(shape =[batch_size, num_features])
			y2 = tf.constant([[1.]] * batch_size)
			discriminator.trainable = False
			gan.train_on_batch(noise, y2)

			# generate images for the GIF as we go
			generate_and_save_images(generator, epoch + 1, seed)

	generate_and_save_images(generator, epochs, seed)

# code
def generate_and_save_images(model, epoch, test_input):
predictions = model(test_input, training = False)

fig = plt.figure(figsize =(10, 10))

for i in range(25):
	plt.subplot(5, 5, i + 1)
	plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap ='binary')
	plt.axis('off')

plt.savefig('image_epoch_{:04d}.png'.format(epoch))
# reshape to add a color map
x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1.
# create batches
dataset = create_batch(x_train_dcgan)
# callthe training function with 10 epochs and record time %% time
train_dcgan(gan, dataset, batch_size, num_features, epochs = 10)
import imageio
import glob

anim_file = 'dcgan_results.gif'

with imageio.get_writer(anim_file, mode ='I') as writer:
filenames = glob.glob('image*.png')
filenames = sorted(filenames)
last = -1
for i, filename in enumerate(filenames):
	frame = 2*(i)
	if round(frame) > round(last):
	last = frame
	else:
	continue
	image = imageio.imread(filename)
	writer.append_data(image)
image = imageio.imread(filename)
writer.append_data(image)
display.Image(filename = anim_file)


=====================================================================================================================================
import numpy as np
import tensorflow as tf
text_data = [
    "The quick brown fox jumps over the lazy dog.",
    "A quick brown fox jumps over a lazy dog.",
    "The lazy dog jumps over the quick brown fox."
]
tokenizer = tf.keras.preprocessing.text.Tokenizer()
tokenizer.fit_on_texts(text_data)
total_words = len(tokenizer.word_index) + 1
input_sequences = []
for line in text_data:
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

max_sequence_len = max([len(x) for x in input_sequences])
input_sequences = np.array(tf.keras.preprocessing.sequence.pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))

xs, labels = input_sequences[:, :-1], input_sequences[:, -1]
# Adjust labels if necessary (e.g., if class indices start from 1)
# labels -= 1  # Uncomment this line if class indices start from 1
ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)

model = tf.keras.models.Sequential([
    tf.keras.layers.Embedding(input_dim=1000, output_dim=64),
    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),
    tf.keras.layers.Dense(total_words, activation='softmax')
])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
# Train the model
history = model.fit(xs, ys, epochs=100, verbose=1)
# Function to generate text
def generate_text(seed_text, next_words, max_sequence_len):
    for _ in range(next_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = tf.keras.preprocessing.sequence.pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')
        predicted_probs = model.predict(token_list)[0]
        predicted_index = np.argmax(predicted_probs)
        output_word = ""
        for word, index in tokenizer.word_index.items():
            if index == predicted_index:
                output_word = word
                break
        seed_text += " " + output_word
    return seed_text

# Test the model
print(generate_text("quick brown", 4, max_sequence_len))
